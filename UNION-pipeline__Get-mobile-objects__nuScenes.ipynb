{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b218758",
   "metadata": {},
   "source": [
    "## UNION: Unsupervised 3D Object Detection using Appearance-based Pseudo-Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f38b3b",
   "metadata": {},
   "source": [
    "![](./figures/figure1-plots/figure1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_results_root = 'PUT_YOUR_DIRECTORY_HERE'\n",
    "data_root                 = 'PUT_YOUR_DIRECTORY_HERE'\n",
    "\n",
    "\n",
    "assert intermediate_results_root!='PUT_YOUR_DIRECTORY_HERE', print('Folder for storing UNION results. Change to directory in your file system!')\n",
    "assert data_root!='PUT_YOUR_DIRECTORY_HERE', print('Directory to nuScenes dataset. Change to directory in your file system!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124b717",
   "metadata": {},
   "source": [
    "## Settings for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775873f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MINI_SPLIT                 = False\n",
    "\n",
    "VISUALIZE_GROUNDTRUTH          = True\n",
    "\n",
    "COMPUTE_GROUNDREMOVAL          = True\n",
    "COMPUTE_SPATIALCLUSTERING      = True\n",
    "COMPUTE_SCENEFLOW              = True\n",
    "COMPUTE_APPEARANCEEMBEDDING    = True\n",
    "COMPUTE_APPEARANCECLUSTERING   = True\n",
    "\n",
    "VISUALIZE_GROUNDREMOVAL        = True\n",
    "VISUALIZE_SPATIALCLUSTERING    = True\n",
    "VISUALIZE_SCENEFLOW            = True\n",
    "VISUALIZE_APPEARANCEEMBEDDING  = True\n",
    "VISUALIZE_APPEARANCECLUSTERING = True\n",
    "\n",
    "first_scene                    = 0\n",
    "num_of_scenes                  = 850"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de01f6a",
   "metadata": {},
   "source": [
    "## Create folder for results\n",
    "\n",
    "\n",
    "Create folder for intermediate results.\n",
    "You need less than 1TB memory for storing everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd138ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(intermediate_results_root):\n",
    "    os.mkdir(intermediate_results_root)\n",
    "print(intermediate_results_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6fee1",
   "metadata": {},
   "source": [
    "## Detection and mobile classes\n",
    "\n",
    "\n",
    "The nuScenes dataset has 10 detection classes:\n",
    "\n",
    "\n",
    "1. Barrier (static)\n",
    "2. Bicycle (static & dynamic)\n",
    "3. Bus (static & dynamic)\n",
    "4. Car (static & dynamic)\n",
    "5. Construction vehicle (static & dynamic)\n",
    "6. Motorcycle (static & dynamic)\n",
    "7. Pedestrian (static & dynamic)\n",
    "8. Traffic cone (static)\n",
    "9. Trailer (static & dynamic)\n",
    "10. Truck (static & dynamic)\n",
    "\n",
    "\n",
    "The classes `barrier` and `traffic cone` do not have the potential to move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_classes = {'movable_object.barrier': 'barrier',\n",
    "                     'vehicle.bicycle': 'bicycle',\n",
    "                     'vehicle.bus.bendy': 'bus',\n",
    "                     'vehicle.bus.rigid': 'bus',\n",
    "                     'vehicle.car': 'car',\n",
    "                     'vehicle.construction': 'construction_vehicle',\n",
    "                     'vehicle.motorcycle': 'motorcycle',\n",
    "                     'human.pedestrian.adult': 'pedestrian',\n",
    "                     'human.pedestrian.child': 'pedestrian',\n",
    "                     'human.pedestrian.construction_worker': 'pedestrian',\n",
    "                     'human.pedestrian.police_officer': 'pedestrian',\n",
    "                     'movable_object.trafficcone': 'traffic_cone',\n",
    "                     'vehicle.trailer': 'trailer',\n",
    "                     'vehicle.truck': 'truck',}\n",
    "\n",
    "mobile_classes = detection_classes.copy()\n",
    "del mobile_classes['movable_object.barrier']\n",
    "del mobile_classes['movable_object.trafficcone']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5063d1",
   "metadata": {},
   "source": [
    "## Create nuScenes object and fill scenes list\n",
    "\n",
    "- `sample_record = nusc.get('sample', sample_token)`\n",
    "- `sensor_data_record = nusc.get('sample_data', sample_sensor_token)`\n",
    "- `sensor_egopose_record = nusc.get('ego_pose', sensor_egopose_token)` \n",
    "- `sensor_pose_record = nusc.get('calibrated_sensor', sensor_pose_token)`\n",
    "- `annot_record = nusc.get('sample_annotation', annot)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e97c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils.splits import train, val\n",
    "from utils.utils_functions import get_scene_information\n",
    "\n",
    "\n",
    "\n",
    "nuscenes_version = 'v1.0-trainval' if not USE_MINI_SPLIT else 'v1.0-mini'\n",
    "nusc             = NuScenes(version=nuscenes_version, dataroot=data_root, verbose=False)\n",
    "\n",
    "\n",
    "scenes = get_scene_information(nusc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1317824f",
   "metadata": {},
   "source": [
    "## Visualize manual annotations (THESE ARE NOT USED DURING TRAINING)\n",
    "\n",
    "\n",
    "Visualize manual annotations.\n",
    "Annotations are only shown if (1) class of the instance is mobile (see above), (2) distance is within 50 meters horizontally from LiDAR frame, and (3) annotation has at least 1 LiDAR point.\n",
    "Points are shown up to 55 meters from LiDAR.\n",
    "Note: Manual annotations are NOT used for computing pseudo-labels with UNION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e52c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALIZE_GROUNDTRUTH:\n",
    "    import ipywidgets\n",
    "    from utils.utils_visualization import plot_manual_annotations\n",
    "    \n",
    "    scene_widget1  = ipywidgets.Dropdown(options=range(len(scenes)))\n",
    "    sample_widget1 = ipywidgets.Dropdown(options=range(len(scenes[0]['sample_tokens'])))   # Indirectly: range(len(scenes[scene_idx]['sample_tokens']))\n",
    "    \n",
    "    def update_sample_indices_range1(*args):\n",
    "        sample_widget1.options = range(len(scenes[scene_widget1.value]['sample_tokens']))\n",
    "    scene_widget1.observe(update_sample_indices_range1, 'value')\n",
    "    \n",
    "    ipywidgets.interact(lambda scene_idx, sample_idx: plot_manual_annotations(nusc=nusc, scene_idx=scene_idx, sample_idx=sample_idx, scenes=scenes, mobile_classes=mobile_classes, annot_range_thres=50.0, num_lidar_points_thres=1,),\n",
    "                        scene_idx=scene_widget1,\n",
    "                        sample_idx=sample_widget1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0fd489",
   "metadata": {},
   "source": [
    "## Component: ground point removal\n",
    "\n",
    "Make a folder for ground removal results (boolean arrays) and one for ground removal results (Ts_coneplane_lidar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f676fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_results_groundremoval_dir1 = os.path.join(intermediate_results_root, 'component_groundremoval1')\n",
    "if not os.path.exists(intermediate_results_groundremoval_dir1):\n",
    "    os.mkdir(intermediate_results_groundremoval_dir1)\n",
    "print(intermediate_results_groundremoval_dir1)\n",
    "\n",
    "\n",
    "intermediate_results_groundremoval_dir2 = os.path.join(intermediate_results_root, 'component_groundremoval2')\n",
    "if not os.path.exists(intermediate_results_groundremoval_dir2):\n",
    "    os.mkdir(intermediate_results_groundremoval_dir2)\n",
    "print(intermediate_results_groundremoval_dir2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f9879b",
   "metadata": {},
   "source": [
    "Remove ground points for all sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db76d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groundremoval_hyperparameters = {'Step0__M': 5,   # Unit: 1.\n",
    "                                 'Step1__xyradius_threshold': 40.00,   # Unit: meters.\n",
    "                                 'Step1__zmin_threshold': -1.84023-1.00,   # Unit: meters.\n",
    "                                 'Step1__zmax_threshold': -1.84023+1.00,   # Unit: meters.\n",
    "                                 'Step2__min_sample_points': 250,   # Unit: 1.\n",
    "                                 'Step2__residual_threshold': 0.10,   # Unit: meters.\n",
    "                                 'Step2__max_trials': 20,   # Unit: 1.\n",
    "                                 'Step3__dmax_thres': 0.30,   # Unit: meters.\n",
    "                                 'Step3__num_cones': 8,   # Unit: 1.\n",
    "                                 'Step3__min_number_cone_points': 500,   # Unit: 1.\n",
    "                                 'Step3__min_sample_points': 250,   # Unit: 1.\n",
    "                                 'Step3__residual_threshold': 0.05,   # Unit: meters.\n",
    "                                 'Step3__max_trials': 20,}   # Unit: 1.\n",
    "\n",
    "\n",
    "if COMPUTE_GROUNDREMOVAL:\n",
    "    from components.component_groundremoval import main__ground_point_removal\n",
    "    main__ground_point_removal(nusc=nusc, scenes=scenes, hyperparameters=groundremoval_hyperparameters, intermediate_results_groundremoval_dir1=intermediate_results_groundremoval_dir1, intermediate_results_groundremoval_dir2=intermediate_results_groundremoval_dir2, first_scene=first_scene, num_of_scenes=num_of_scenes if not USE_MINI_SPLIT else 10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8851ab07",
   "metadata": {},
   "source": [
    "Visualize the ground removal results.\n",
    "Points are shown up to 50 meters from LiDAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ee641",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALIZE_GROUNDREMOVAL:\n",
    "    import ipywidgets\n",
    "    from utils.utils_visualization import plot_ground_segmented_sweep\n",
    "    \n",
    "    scene_widget2 = ipywidgets.Dropdown(options=range(len(scenes)))\n",
    "    sweep_widget2 = ipywidgets.Dropdown(options=range(len(scenes[0]['sweep_lidar_tokens'])))   # Indirectly: range(len(scenes[scene_idx]['sweep_lidar_tokens']))\n",
    "    \n",
    "    def update_sweep_indices_range2(*args):\n",
    "        sweep_widget2.options = range(len(scenes[scene_widget2.value]['sweep_lidar_tokens']))\n",
    "    scene_widget2.observe(update_sweep_indices_range2, 'value')\n",
    "    \n",
    "    ipywidgets.interact(lambda scene_idx, sweep_idx: plot_ground_segmented_sweep(nusc=nusc, scenes=scenes, intermediate_results_groundremoval_dir1=intermediate_results_groundremoval_dir1, scene_idx=scene_idx, sweep_idx=sweep_idx,),\n",
    "                        scene_idx=scene_widget2,\n",
    "                        sweep_idx=sweep_widget2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75401d0",
   "metadata": {},
   "source": [
    "## Component: spatial clusterting\n",
    "\n",
    "Make a folder for spatial clustering results (cluster_dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_results_spatialclustering_dir = os.path.join(intermediate_results_root, 'component_spatialclustering')\n",
    "if not os.path.exists(intermediate_results_spatialclustering_dir):\n",
    "    os.mkdir(intermediate_results_spatialclustering_dir)\n",
    "print(intermediate_results_spatialclustering_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d8434",
   "metadata": {},
   "source": [
    "Cluster the points for all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c91eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatialclustering_hyperparameters = {'Step0__M': 7,   # Unit: 1.\n",
    "                                     'Step1__sky_threshold': 4.00,   # Unit: meters.\n",
    "                                     'Step1__range_threshold': 55.00,   # Unit: meters.\n",
    "                                     'Step1__x_range_threshold': None,   # Unit: meters.\n",
    "                                     'Step1__y_range_threshold': None,   # Unit: meters.\n",
    "                                     'Step2__clustersize_threshold': 16,   # Unit: 1.\n",
    "                                     'Step2__cluster_selection_epsilon': 0.50,   # Unit: meters.\n",
    "                                     'Step3__num_cones': groundremoval_hyperparameters['Step3__num_cones'],   # Unit: 1.\n",
    "                                     'Step4__length_max_threshold': 20.00,   # Unit: meters.\n",
    "                                     'Step4__width_max_threshold': 6.00,   # Unit: meters.\n",
    "                                     'Step4__height_min_threshold': 0.25,   # Unit: meters.\n",
    "                                     'Step4__height_above_ground_max_threshold': 0.75,   # Unit: meters.\n",
    "                                     'Step4__length_width_max_ratio_threshold': 8,   # Unit: 1.\n",
    "                                     'Step4__area_min_threshold': 0.25,}   # Unit: square meters.\n",
    "\n",
    "\n",
    "if COMPUTE_SPATIALCLUSTERING:\n",
    "    from components.component_spatialclustering import main__spatial_clustering\n",
    "    main__spatial_clustering(nusc=nusc, scenes=scenes, hyperparameters=spatialclustering_hyperparameters, intermediate_results_groundremoval_dir1=intermediate_results_groundremoval_dir1, intermediate_results_groundremoval_dir2=intermediate_results_groundremoval_dir2, intermediate_results_spatialclustering_dir=intermediate_results_spatialclustering_dir, first_scene=first_scene, num_of_scenes=num_of_scenes if not USE_MINI_SPLIT else 10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea66f8",
   "metadata": {},
   "source": [
    "Visualize the spatial clustering results, i.e. fitted spatial clusters and fitted bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALIZE_SPATIALCLUSTERING:\n",
    "    import ipywidgets\n",
    "    from utils.utils_visualization import plot_spatial_clusters\n",
    "    \n",
    "    scene_widget3  = ipywidgets.Dropdown(options=range(len(scenes)))\n",
    "    sample_widget3 = ipywidgets.Dropdown(options=range(len(scenes[0]['sample_tokens'])))   # Indirectly: range(len(scenes[scene_idx]['sample_tokens']))\n",
    "    dense_widget3  = ipywidgets.Dropdown(options=[False,True])\n",
    "    bbox_widget3   = ipywidgets.Dropdown(options=[False,True])\n",
    "    map_widget3    = ipywidgets.Dropdown(options=[False,True])\n",
    "    \n",
    "    def update_sample_indices_range3(*args):\n",
    "        sample_widget3.options = range(len(scenes[scene_widget3.value]['sample_tokens']))\n",
    "    scene_widget3.observe(update_sample_indices_range3, 'value')\n",
    "    \n",
    "    ipywidgets.interact(lambda scene_idx, sample_idx, dense, bbox: plot_spatial_clusters(nusc=nusc, scenes=scenes, M=spatialclustering_hyperparameters['Step0__M'], intermediate_results_spatialclustering_dir=intermediate_results_spatialclustering_dir, scene_idx=scene_idx, sample_idx=sample_idx, dense=dense, bbox=bbox,),\n",
    "                        scene_idx=scene_widget3,\n",
    "                        sample_idx=sample_widget3,\n",
    "                        dense=dense_widget3,\n",
    "                        bbox=bbox_widget3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8034f",
   "metadata": {},
   "source": [
    "## Component: scene flow estimation\n",
    "\n",
    "Make a folder for scene flow estimation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_results_sceneflow_dir = os.path.join(intermediate_results_root, 'component_sceneflow')\n",
    "if not os.path.exists(intermediate_results_sceneflow_dir):\n",
    "    os.mkdir(intermediate_results_sceneflow_dir)\n",
    "print(intermediate_results_sceneflow_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d174c7",
   "metadata": {},
   "source": [
    "Compute velocity for all clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25618baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sceneflow_hyperparameters = {'Step0__M': spatialclustering_hyperparameters['Step0__M'],   # Unit: 1.\n",
    "                             'Step0__T': 5,   # Unit: 1.\n",
    "                             'Step1__bottom_drop_thres': 0.25,   # Unit: meters.\n",
    "                             'Step1__top_drop_thres': 2.50,   # Unit: meters.\n",
    "                             'Step1__min_points_per_pc_thres': 16,   # Unit: 1.\n",
    "                             'Step1__search_size': 4.00,   # Unit: meters.\n",
    "                             'Step1__search_step': 0.10,   # Unit: meters.\n",
    "                             'Step1__max_icp_iterations': 10,   # Unit: 1.\n",
    "                             'Step1__max_dist_inlier_thres': 0.30,   # Unit: meters.\n",
    "                             'Step1__max_pc_size': 800,   # Unit: 1.\n",
    "                             'Step2__max_dist_inlier_thres': 0.30,   # Unit: meters.\n",
    "                             'Step3__search_size': 20.00,   # Unit: meters.\n",
    "                             'Step3__search_step': 0.10,   # Unit: meters.\n",
    "                             'Step3__max_icp_iterations': 10,   # Unit: 1.\n",
    "                             'Step3__max_dist_inlier_thres': 0.30,   # Unit: meters.\n",
    "                             'Step4__num_cones': groundremoval_hyperparameters['Step3__num_cones'],   # Unit: 1.\n",
    "                             'Step4__lidar_frequency': 20,}   # Unit: Hertz.\n",
    "\n",
    "\n",
    "if COMPUTE_SCENEFLOW:\n",
    "    from components.component_sceneflow import main__scene_flow\n",
    "    main__scene_flow(nusc=nusc, scenes=scenes, hyperparameters=sceneflow_hyperparameters, intermediate_results_groundremoval_dir2=intermediate_results_groundremoval_dir2, intermediate_results_spatialclustering_dir=intermediate_results_spatialclustering_dir, intermediate_results_sceneflow_dir=intermediate_results_sceneflow_dir, first_scene=first_scene, num_of_scenes=num_of_scenes if not USE_MINI_SPLIT else 10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a6003",
   "metadata": {},
   "source": [
    "Visualize the motion status, i.e. dynamic object proposals in red.\n",
    "Points are shown up to 50 meters from LiDAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALIZE_SCENEFLOW:\n",
    "    import ipywidgets\n",
    "    from utils.utils_visualization import plot_motion_status\n",
    "    \n",
    "    scene_widget4  = ipywidgets.Dropdown(options=range(len(scenes)))\n",
    "    sample_widget4 = ipywidgets.Dropdown(options=range(len(scenes[0]['sample_tokens'])))   # Indirectly: range(len(scenes[scene_idx]['sample_tokens']))\n",
    "    dense_widget4  = ipywidgets.Dropdown(options=[False,True])\n",
    "    bbox_widget4   = ipywidgets.Dropdown(options=[False,True])\n",
    "    label_widget4  = ipywidgets.Dropdown(options=[False,True])\n",
    "    \n",
    "    def update_sample_indices_range4(*args):\n",
    "        sample_widget4.options = range(len(scenes[scene_widget4.value]['sample_tokens']))\n",
    "    scene_widget4.observe(update_sample_indices_range4, 'value')\n",
    "    \n",
    "    ipywidgets.interact(lambda scene_idx, sample_idx, dense, bbox, label: plot_motion_status(nusc=nusc, scenes=scenes, M=spatialclustering_hyperparameters['Step0__M'], intermediate_results_sceneflow_dir=intermediate_results_sceneflow_dir, scene_idx=scene_idx, sample_idx=sample_idx, dense=dense, bbox=bbox, label=label,),\n",
    "                        scene_idx=scene_widget4,\n",
    "                        sample_idx=sample_widget4,\n",
    "                        dense=dense_widget4,\n",
    "                        bbox=bbox_widget4,\n",
    "                        label=label_widget4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0204355b",
   "metadata": {},
   "source": [
    "## Component: appearance embedding (including unsupervised encoding)\n",
    "\n",
    "Make a folder for feature map results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40885553",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_results_appearanceembedding_dir = os.path.join(intermediate_results_root, 'component_appearanceembedding_dinov2-vitl14-reg')\n",
    "if not os.path.exists(intermediate_results_appearanceembedding_dir):\n",
    "    os.mkdir(intermediate_results_appearanceembedding_dir)\n",
    "print(intermediate_results_appearanceembedding_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091254f3",
   "metadata": {},
   "source": [
    "Compute appearance embedding for all clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c76011",
   "metadata": {},
   "outputs": [],
   "source": [
    "appearanceembedding_hyperparameters = {'Step0__stride': 14,}   # Unit:1.\n",
    "\n",
    "\n",
    "if COMPUTE_APPEARANCEEMBEDDING:\n",
    "    from components.component_appearanceembedding import main__appearance_embedding\n",
    "    main__appearance_embedding(nusc=nusc, scenes=scenes, hyperparameters=appearanceembedding_hyperparameters, intermediate_results_spatialclustering_dir=intermediate_results_spatialclustering_dir, intermediate_results_appearanceembedding_dir=intermediate_results_appearanceembedding_dir, first_scene=first_scene, num_of_scenes=num_of_scenes if not USE_MINI_SPLIT else 10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345c617c",
   "metadata": {},
   "source": [
    "Visualize the appearance embedding results by coloring the clusters reddish based on cosine similarity with a reference cluster (indicated in blue).\n",
    "Points are shown up to 50 meters from LiDAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf185da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALIZE_APPEARANCEEMBEDDING:\n",
    "    import ipywidgets\n",
    "    from utils.utils_visualization import plot_appearance_similarities\n",
    "    \n",
    "    scene_widget5   = ipywidgets.Dropdown(options=range(len(scenes)))\n",
    "    sample_widget5  = ipywidgets.Dropdown(options=range(len(scenes[0]['sample_tokens'])))   # Indirectly: range(len(scenes[scene_idx]['sample_tokens']))\n",
    "    dense_widget5   = ipywidgets.Dropdown(options=[False,True])\n",
    "    bbox_widget5    = ipywidgets.Dropdown(options=[False,True])\n",
    "    cluster_widget5 = ipywidgets.Dropdown(options=range(100))\n",
    "    label_widget5   = ipywidgets.Dropdown(options=[True,False])\n",
    "    \n",
    "    def update_sample_indices_range5(*args):\n",
    "        sample_widget5.options = range(len(scenes[scene_widget5.value]['sample_tokens']))\n",
    "    scene_widget5.observe(update_sample_indices_range5, 'value')\n",
    "    \n",
    "    ipywidgets.interact(lambda scene_idx, sample_idx, dense, bbox, cluster_idx, label: plot_appearance_similarities(nusc=nusc, scenes=scenes, M=spatialclustering_hyperparameters['Step0__M'], intermediate_results_spatialclustering_dir=intermediate_results_spatialclustering_dir, intermediate_results_appearanceembedding_dir=intermediate_results_appearanceembedding_dir, scene_idx=scene_idx, sample_idx=sample_idx, dense=dense, bbox=bbox, cluster_idx=cluster_idx, label=label,),\n",
    "                        scene_idx=scene_widget5,\n",
    "                        sample_idx=sample_widget5,\n",
    "                        dense=dense_widget5,\n",
    "                        bbox=bbox_widget5,\n",
    "                        cluster_idx=cluster_widget5,\n",
    "                        label=label_widget5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e564db23",
   "metadata": {},
   "source": [
    "## Component: appearance clustering\n",
    "\n",
    "Make a folder for appearance clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_results_appearanceclustering_dir = os.path.join(intermediate_results_root, 'component_appearanceclustering_dinov2-vitl14-reg')\n",
    "if not os.path.exists(intermediate_results_appearanceclustering_dir):\n",
    "    os.mkdir(intermediate_results_appearanceclustering_dir)\n",
    "print(intermediate_results_appearanceclustering_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4ba5a9",
   "metadata": {},
   "source": [
    "Cluster appearance embeddings and obtain mobile objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4872bed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "appearanceclustering_hyperparameters = {'Step0__feature_dim': 1024,   # Unit: 1.\n",
    "                                        'Step1__K__class_agnostic': 20,   # Unit: 1.\n",
    "                                        'Step1__max_iterations': 5000,   # Unit: 1.\n",
    "                                        'Step1__num_init': 10,   # Unit: 1.\n",
    "                                        'Step2__velocity_thres': 0.50,   # Unit: m/s.\n",
    "                                        'Step2__moving_fraction_thres': 0.050,   # Unit: 1.\n",
    "                                        'Step4__K__multi_class_list': [5, 10, 15, 20],   # Unit: 1.\n",
    "                                        'Step4__max_iterations': 5000,   # Unit: 1.\n",
    "                                        'Step4__num_init': 10,}   # Unit: 1.\n",
    "\n",
    "\n",
    "if COMPUTE_APPEARANCECLUSTERING:\n",
    "    from components.component_appearanceclustering import main__appearance_clustering\n",
    "    main__appearance_clustering(nusc=nusc, scenes=scenes, hyperparameters=appearanceclustering_hyperparameters, intermediate_results_sceneflow_dir=intermediate_results_sceneflow_dir, intermediate_results_appearanceembedding_dir=intermediate_results_appearanceembedding_dir, intermediate_results_appearanceclustering_dir=intermediate_results_appearanceclustering_dir, first_scene=first_scene, num_of_scenes=num_of_scenes if not USE_MINI_SPLIT else 10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e914f91",
   "metadata": {},
   "source": [
    "Visualize velocity fractions per appearance cluster.\n",
    "Velocity fractions are sorted based on value.\n",
    "Non-mobile and mobile clusters are indicated in blue and orange, respectively.\n",
    "This is Figure 4 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ba325",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALIZE_APPEARANCECLUSTERING:\n",
    "    from utils.utils_visualization import plot_velocity_fractions\n",
    "    plot_velocity_fractions(hyperparameters=appearanceclustering_hyperparameters, intermediate_results_appearanceclustering_dir=intermediate_results_appearanceclustering_dir,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557db959",
   "metadata": {},
   "source": [
    "Visualize mobile objects. Points are shown up to 50 meters from LiDAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALIZE_APPEARANCECLUSTERING:\n",
    "    import ipywidgets\n",
    "    from utils.utils_visualization import plot_mobile_objects\n",
    "    \n",
    "    scene_widget6  = ipywidgets.Dropdown(options=range(len(scenes)))\n",
    "    sample_widget6 = ipywidgets.Dropdown(options=range(len(scenes[0]['sample_tokens'])))   # Indirectly: range(len(scenes[scene_idx]['sample_tokens']))\n",
    "    dense_widget6  = ipywidgets.Dropdown(options=[False,True])\n",
    "    bbox_widget6   = ipywidgets.Dropdown(options=[False,True])\n",
    "    label_widget6  = ipywidgets.Dropdown(options=[False,True])\n",
    "    \n",
    "    def update_sample_indices_range6(*args):\n",
    "        sample_widget6.options = range(len(scenes[scene_widget6.value]['sample_tokens']))\n",
    "    scene_widget6.observe(update_sample_indices_range6, 'value')\n",
    "    \n",
    "    ipywidgets.interact(lambda scene_idx, sample_idx, dense, bbox, label: plot_mobile_objects(nusc=nusc, scenes=scenes, M=spatialclustering_hyperparameters['Step0__M'], hyperparameters=appearanceclustering_hyperparameters, intermediate_results_sceneflow_dir=intermediate_results_sceneflow_dir, intermediate_results_appearanceclustering_dir=intermediate_results_appearanceclustering_dir, scene_idx=scene_idx, sample_idx=sample_idx, dense=dense, bbox=bbox, label=label,),\n",
    "                        scene_idx=scene_widget6,\n",
    "                        sample_idx=sample_widget6,\n",
    "                        dense=dense_widget6,\n",
    "                        bbox=bbox_widget6,\n",
    "                        label=label_widget6,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b9a883",
   "metadata": {},
   "source": [
    "Visualize (a) HDBSCAN, (b) Scene Flow, (c) UNION, and (d) Ground Truth bounding boxes for scene-1100.\n",
    "This is Figure 3 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba00569",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALIZE_APPEARANCECLUSTERING:\n",
    "    from utils.utils_visualization import plot_qualitative_example\n",
    "    plot_qualitative_example(nusc=nusc, scenes=scenes, hyperparameters=appearanceclustering_hyperparameters, intermediate_results_spatialclustering_dir=intermediate_results_spatialclustering_dir, intermediate_results_sceneflow_dir=intermediate_results_sceneflow_dir, intermediate_results_appearanceclustering_dir=intermediate_results_appearanceclustering_dir, USE_MINI_SPLIT=USE_MINI_SPLIT, mobile_classes=mobile_classes, load_reference=True,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
